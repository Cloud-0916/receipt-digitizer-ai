# 📋 プロジェクト振り返り：レシートデジタル化AI

## 【プロジェクト概要】

| 項目 | 内容 |
|------|------|
| 期間 | 約1ヶ月（週10〜15時間） |
| 成果物 | Webブラウザ上で動作するレシートデジタル化アプリ |
| URL | https://cloud-0916-receipt-digitizer-ai-app-ikvtjm.streamlit.app |
| GitHub | https://github.com/Cloud-0916/receipt-digitizer-ai |

---

## 【1週目：環境構築・画像前処理】

### ステップ1：開発環境の構築

**やったこと：**
- GitHubリポジトリ作成
- Python仮想環境（venv）の構築
- `.gitignore` の設定（APIキーの漏洩防止）

**面接での説明例：**
> 「最初にGitで管理する環境を整えました。特に`.gitignore`でAPIキーを含む`.env`ファイルを除外し、セキュリティを意識した開発を心がけました。」

---

### ステップ2：テストデータの準備

**やったこと：**
- スマホでレシートを5〜10枚撮影
- 意図的に「影付き」「暗い画像」も含めた

**面接での説明例：**
> 「実際の利用シーンを想定し、条件の悪い画像もテストデータに含めました。これにより、後の前処理の重要性を実感できました。」

---

### ステップ3：画像前処理の実装（preprocessing.py）

**最初の実装：大津の二値化**
```python
_, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
```

**発生した問題：**
- 影付き画像で影の部分が黒く塗りつぶされた

**解決策：適応的二値化に変更**
```python
binary = cv2.adaptiveThreshold(
    denoised, 255,
    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
    cv2.THRESH_BINARY, 11, 2
)
```

**面接での説明例：**
> 「当初は大津の二値化を使用しましたが、影付き画像で文字が黒く塗りつぶされる問題が発生しました。これは大津の二値化が画像全体で1つの閾値を決めるためです。そこで、局所領域ごとに閾値を計算する適応的二値化に変更し、照明ムラにも対応できるようにしました。」

---

## 【2週目：OCR・LLM実装】

### ステップ4：OCRエンジンの実装（ocr_engine.py）

**最初の選択：Tesseract**

**発生した問題：**
- 日本語レシートの認識精度が非常に低い
- 文字化けが多発

**解決策：EasyOCRに変更**
```python
import easyocr
reader = easyocr.Reader(['ja', 'en'])
```

**比較結果：**
| エンジン | 日本語精度 | 処理速度 |
|---------|-----------|---------|
| Tesseract | △ 低い | ○ 速い |
| EasyOCR | ○ 高い | △ やや遅い |

**面接での説明例：**
> 「最初は無料で軽量なTesseractを試しましたが、日本語レシートでは認識精度が低く、ほぼ読み取れませんでした。比較検証の結果、EasyOCRの方が日本語認識精度が高かったため切り替えました。処理速度は劣りますが、精度を優先しました。」

---

### ステップ5：LLMによる構造化（llm_parser.py）

**API選定の経緯：**

| API | 状況 |
|-----|------|
| OpenAI API | 有料のため見送り |
| Google Gemini API | 無料枠の上限に達した |
| Groq API（Llama 3.3） | 無料で高速、採用 |

**プロンプト設計のポイント：**
```python
prompt = """以下のテキストはレシートをOCRした結果です。
誤字脱字が含まれる可能性があります。
このテキストから情報を抽出し、以下のJSON形式のみを出力してください。
余計な解説は不要です。不明な場合はnullを入れてください。
..."""
```

**ハルシネーション対策：**
- 「不明な場合はnullを返す」と明示的に指示
- 余計な解説を出力しないよう制約

**面接での説明例：**
> 「LLMのAPI選定では、最初はGemini APIを使いましたが、無料枠の上限に達したためGroq APIに切り替えました。Groq APIはLlama 3.3を無料で高速に使えます。プロンプト設計では、OCRの誤読を前提として指示し、不明な場合はnullを返すことでハルシネーションを防いでいます。」

---

## 【3週目：Streamlitアプリ化】

### ステップ6：UIの構築（app.py）

**実装した機能：**
1. ファイルアップローダー（ドラッグ＆ドロップ対応）
2. 元画像と処理済み画像の並列表示
3. OCR結果のテキスト表示
4. 構造化データ（JSON）の表示
5. テーブル形式での表示
6. CSVダウンロードボタン

**面接での説明例：**
> 「Streamlitを選んだ理由は、Pythonだけで完結し、迅速にプロトタイプを作れるからです。UIでは、ユーザーが処理の過程を確認できるよう、元画像・処理済み画像・OCR結果・構造化データを段階的に表示しています。」

---

### ステップ7：パイプラインの結合

**処理フロー：**
```
画像アップロード
    ↓
前処理（preprocessing.py）
    ↓
OCR（ocr_engine.py）
    ↓
LLM構造化（llm_parser.py）
    ↓
CSV出力
```

**面接での説明例：**
> 「各モジュールを疎結合に設計し、それぞれ単体でテストできるようにしました。これにより、例えばOCRエンジンを別のものに差し替えることも容易です。」

---

## 【4週目：ドキュメント・デプロイ】

### ステップ8：README.mdの作成

**含めた内容：**
- プロジェクト概要
- システムアーキテクチャ図
- 技術スタック（選定理由付き）
- 技術的なハイライト（課題と解決策）
- セットアップ手順
- 今後の改善計画

**面接での説明例：**
> 「READMEは採用担当者が最初に見る部分なので、技術選定の理由や直面した課題・解決策を明記しました。単なる使い方だけでなく、エンジニアとしての思考過程が伝わるよう意識しました。」

---

### ステップ9：デプロイ

**発生した問題：**
- `requirements.txt` の依存関係エラー
- pandas/numpyのバージョン競合

**解決策：**
- バージョン指定を外したシンプルな `requirements.txt` に変更

```
streamlit
opencv-python-headless
easyocr
groq
python-dotenv
pandas
numpy
pillow
```

**面接での説明例：**
> 「デプロイ時にPythonバージョンやライブラリの依存関係でエラーが発生しました。ローカル環境との差異を解消するため、バージョン指定を最小限にした `requirements.txt` を作成し、Streamlit Cloud側に互換性のあるバージョンを選ばせることで解決しました。」

---

## 【面接想定Q&A】

### Q1：「なぜCloud Vision APIなどの高精度な有料APIを使わなかったのですか？」

> **回答例：**「まずは画像処理の基礎（OpenCV）を学び、ローカルでの実装力をつけたかったからです。また、無料で使える技術の限界を理解した上で、実務でスピードと精度が優先される場合はCloud Vision APIへの切り替えも容易な設計にしています。」

---

### Q2：「LLMがハルシネーション（誤情報）を返す対策は？」

> **回答例：**「プロンプトで『不明な場合はnullを返す』と明示的に指示しています。また、余計な解説を出力しないよう制約しています。次の改善ステップとして、UI上でユーザーが結果を修正できるフォームの実装を検討しています。」

---

### Q3：「このプロジェクトで最も苦労した点は？」

> **回答例：**「OCRの精度向上が最も苦労しました。Tesseractでは日本語がほぼ認識できず、EasyOCRに切り替えても完璧ではありません。しかし、LLMのコンテキスト理解能力で誤読を補正するアプローチを取ることで、実用的なレベルにできました。画像処理→OCR→LLMの組み合わせで精度を補完し合う設計が重要だと学びました。」

---

### Q4：「今後の改善点は？」

> **回答例：**
> 1. **OCR精度向上**：Google Cloud Vision APIの導入検討
> 2. **複数レシート対応**：一括処理機能の追加
> 3. **ユーザー修正機能**：抽出結果を手動で修正できるUI
> 4. **データ永続化**：抽出したデータをDBに保存

---

### Q5：「このプロジェクトで学んだことは？」

> **回答例：**
> - 画像前処理がOCR精度に与える影響の大きさ
> - 無料API枠内での開発手法とトラブルシューティング
> - LLMプロンプト設計によるハルシネーション対策
> - Streamlitを用いた迅速なプロトタイピング
> - デプロイ時の依存関係管理の重要性

---

## 【技術スタック一覧】

| カテゴリ | 技術 | 選定理由 |
|---------|------|----------|
| 言語 | Python 3.12 | AI/ML領域での豊富なライブラリ |
| 画像処理 | OpenCV | 高速な画像処理、豊富な前処理機能 |
| OCR | EasyOCR | 日本語対応、Tesseractより高精度 |
| LLM | Groq API (Llama 3.3) | 無料枠あり、高速推論 |
| UI | Streamlit | Pythonのみで完結、迅速なプロトタイピング |
| デプロイ | Streamlit Cloud | 無料、GitHub連携が簡単 |

---

## 【主要コマンド一覧】

```bash
# 仮想環境の有効化
.\venv\Scripts\Activate

# アプリの起動
streamlit run app.py

# 依存関係のインストール
pip install -r requirements.txt

# Gitへのプッシュ
git add .
git commit -m "コミットメッセージ"
git push origin main
```

---

**作成日：2026年1月**
